<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[java工具类]]></title>
    <url>%2F2017%2F06%2F20%2Fjava-utils%2F</url>
    <content type="text"><![CDATA[GitHub上前16名的Java工具类 在Java中，工具类就是一个定义了一组执行常用功能方法的类。programcreek统计了最常用的Java工具类及其常用方法。数据来自GitHub随机选择的50,000个开源Java项目。 下面是前16位的最受欢迎的工具类和方法，收藏一下以便在需要的时候不需要自己重复发明轮子。 方法的名称通常就表示其功能。]]></content>
      <tags>
        <tag>java utils</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web高并发案例分析]]></title>
    <url>%2F2017%2F06%2F09%2Fcurrent-case%2F</url>
    <content type="text"><![CDATA[一般来说web高并发需要解决的问题如下： 1.应用服务器的高并发 2.数据库的高并发 持久化的数据mysql或者oracle（关系型） 缓存型数据库redis或者memcache（非关系型） 一、应用服务器的高并发一般应用服务器的架构都是对台tomcat，加上一台nginx反向代理服务器组成一个小型集群，这样虽然可以承受的住一般的高并发访问，但是对于高并发的话，就有些吃紧。可能大家会觉得tomcat可以不断水平扩容，这样就可以承受的住高并发访问，但是要知道一点，一台nginx服务不管怎么去优化（提升服务器的硬件配置），她的并发数终究是有限的，当达到十万级时，一台代理服务器时扛不住这么大的并发数的，因为需要多台nginx组成一个集群，自己可以搭建个均衡负载器，但是工作量很大，对于没有这方面经验来说，可以使用腾讯云的均衡负载器。每次需要扩容时，可以看看系统还能不能继续优化，比如看看：tomcat和jvm参数设置是不是最优等。 二、对于数据库的并发，一般包括持久化数据库和缓存数据的并发1. 对于持久化的数据库，对于sql，能够适当增加索引，sql技巧等来优化数据库，如果不行，再采用垂直和水平分表，垂直和水平分库，分区以及读写分离等操作。1.1 sql技巧：一般业务下都会有按时间降序的要求，此时可以根据主键id进行降序排序，一样能达到业务要去，但是这种方法要快速很多。 1.2 垂直分表：把不常用或业务逻辑不紧密或存储内容比较多的字段分到新的表中可使表存储更多数据。另外垂直分割可以使得数据行变小，一个数据页就能存放更多的数据，在查询时就会减少I/O次数和增加缓存的命中率。其缺点是需要管理冗余列，查询所有数据需要join操作。 1.3 水平分表：一般来说，水平分表更多的是采用某种策略，比如存放游戏日志，这里先不讨论用mongodb或者habse来存储，我们可以按天，星期或者月来分表，至于采用哪种根据表的产生数据的速度，另外，我们再根据日期进行分表的同时，还可以根据用户的唯一性标识进行分表，比如：用身份标识（qq）,我们可以根据qq的后两位根据分表，这样最多是100张表，为了限制单张表的数据无限增长，可以做个任务定时器去定时清楚表的数据，最好保持在10万以下；冷热数据存储也是水平分表的另一种方法。 1.4 垂直分库：垂直分库在“微服务”盛行的今天已经非常普及了。基本的思路就是按照业务模块来划分出不同的数据库，而不是像早期一样将所有的数据表都放到同一个数据库中。 比如：对于游戏日志放到一个数据库，在这里就要考虑到在高并发场景下，垂直分库一定程度上能够突破IO、连接数及单机硬件资源的瓶颈，是大型分布式系统中优化数据库架构的重要手段。但是也会遇到很多问题，例如：跨库join，分布式事务等。 1.5 水平分库: 与上面讲到的水平分表的思想相同，唯一不同的就是将这些拆分出来的表保存在不同的数据中。这也是很多大型互联网公司所选择的做法。某种意义上来讲，有些系统中使用的”冷热数据分离”（将一些使用较少的历史数据迁移到其他的数据库中。而在业务功能上，通常默认只提供热点数据的查询），也是类似的实践。在高并发和海量数据的场景下，分库能够有效缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源的瓶颈。当然，投入的硬件成本也会更高。同时，这也会带来一些复杂的技术问题和挑战（例如：跨分片的复杂查询，跨分片事务等） 1.6 分区： 1.7 读写分离： 2.缓存数据库redis单点：一般来说系统初期的话，redis都是单点，单点的坏处就是并发数有点，可用性差，可扩性差。在改变架构之前，最好看看原先redis性能能不能优化，一般优化包括配置参数，内存，命中率，对于内存，如果对key能设置过期时间过好设置过期时间并且采用合适的数据淘汰算法，在这里切记对于可能无限增长的key一定注意，比如：time key,每隔10秒设置一个key缓存，这样的话，一年下来就可能有50多万的key,想想就可怕，这样的话可能就要换个数据接口进行存储，或者加上过期时间，再或者换个其他方法，所以在设置key最好想清楚用什么数据接构存储，能不能加上过期时间，最后考虑全局使用合适的数据淘汰算法。 分布式：随着系统的并发数越来越大，可以扩展redis成分布式redis，在这里除了要清楚运维的操作方面：a.增加和移除主从节点 b.重新分片在这里移除主节点需要注意两点：a.先移除主节点的slot b.如果主节点有从节点，会从主节点下的所有的从节点进行选举一个成为主节点，所以一定要确保所有的从节点的本地dump数据文件不能为空；还需要考虑分布式锁和分布式事物。 分布式锁： 分布式事务： 三、小结1.对于应用服务器的高并发： 采用多nginx+多tomcat集群模式，这里还可以根据服务的划分（soa），把复杂的系统划分为一个个子服务，服务之间访问可以采用http+json，也可以采用RPC，一般来说RPC适合内网通信，http+json适合外网通信，当然RPC各个方面的性能都要比http要，其次分布式的节点也可以作为一个集群来部署，这样就能非常高的并发数。 2.数据库的高并发：前面讲了很常见的mysql和redis，在大型网站中数据量是非常大的，对于某些业务每天可能都会生成十万级，百万级，甚至千万级的数据的来书，mysql无疑是够呛的，这时可以考虑使用mongodb或者hbase. 四、案例分析1.文章阅读数增加 一般会用到redis, mysql, 异步消息队列系统（redis：优点：低延迟，缺点：no have ack），具体操作：首先对redis的数据进行加jedisClient.hincrBy(RDU.READ_COUNT, id, 1)，然后返回数据，之后的数据持久化操作就交给redis异步消息系统，这里需要考虑三个fail点：a.redis fail直接返回错误提示 b.请求发送失败 c.异步消息系统处理持久化失败对于第一个我们并不care；第二个请求发送失败（失败点：网络连接失败），这里我们没必要关注这种概率极低的现象，因为你要考虑要技术实现的成本与时间的问题，并且每次发送个异步消息的数据都是最新点赞数，就算出现问题只要再次持久化到数据库就行；第三个异步消息处理失败我们可以做好系统的监控与预警，及时处理失败的业务。 扩展：单点的redis并发数有限，可用性差，可扩性差，可以搭建redis集群来解决这个问题，对于一些可能重要的业务数据需要ack来说，可以采用阿里的racketmq，对于一些不重要的业务数据，丢失也没什么关系，比如：日志处理，可以采用kafka，她无疑是mq性能中的巨无霸。 2.文章搜索 这里不讨论如何实现文章的搜索，文章搜索的实现会在另一篇文章中进行总结分享。一般除了要返回查询的文章的数据，还需要对用户行为的日志进行记录，用于统计和分析用户的行为，方便平台能够能好的迎合用户的需求，这里的日志输入采用了slf4j+logback，日志收集采用了ftp，日志存储采用了mongodb，日志统计与分析可用spring tsak定时任务定统计，展现给分析人员进行分析。这里的除了日志输出在本系统，其他都可以交给日志分析系统，也就是统计系统来做，可以提高单个系统的并发和降低系统的耦合度，日志分析系统主要采用了slf4j+logback+ftp+mongodb,当然还可以采用性能更优的slf4j+logback+kafka+mongodb+Elasticsearch+kibana，其中Elasticsearch是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等，kibana也是一个开源和免费的工具，他Kibana可以为ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助您汇总、分析和搜索重要数据日志。 五、总结对于高并发的Web系统，一般都会用到集群，分布式，分布式缓存，分布式消息队列，分布式日志收集等技术，这些技术不仅能解决高并发的问题，还可以构建高并发，高流量，高性能，高可用以及可扩展的大型web系统。 作者 [soar]2017 年 06月 09日]]></content>
      <tags>
        <tag>current</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何快速的解决线上的问题]]></title>
    <url>%2F2017%2F06%2F08%2Fsolve-question%2F</url>
    <content type="text"><![CDATA[问题：在多线程和高并发环境下，如果有一个平均运行一百万次才出现一次的bug，你如何调试这个bug？ 先问清楚bug是属于哪一类，是崩溃？还是数据不一致？以及对基于这个bug的业务对系统造成的影响严不严重然后尽可能的问更多的资料，才能考虑用什么方法。在考虑用什么方法之前应该从管理上要考虑bug的严重性与成本/时间的问题。 1.选择解决问题的方法，无非就两种： a.解决 b.回退版本+解决，以确保正常业务不出问题 如果bug的严重性大，并且不能马上（1-3分钟）解决问题的话，采用a方法； 如果bug的严重性不大， 采用b方法。 2.无论选择哪种，都要去解决bug，在解决bug之前，尽量保留现场，有利于快速的去解决问题，具体方法如下(都是在测试环境进行):a.重现。一般来说能重现的问题都不是问题，如果事先已经打印了日志，可以根据日志去重现问题， 否则可以根据review code+压力测试去重现问题，如果重现出了问题进行c步骤，否则进行b步骤; b.加大测试力度或者采取别的测试方法去重现问题 c.定位和Reduce(逐步收窄范围)，定位可以采取日志跟踪，断点调试，或者软件调式都可以， 在定位的过程中最逐步的去收窄范围，这样有利于解决快速的定位出问题； d.在定位出了问题之后再次考虑bug的严重性与成本/时间的问题，看需不需要去解决。 3.如果最终能找出问题，需要研究怎样防范相似的 bug。4.总结一般来说，如果是核心业务，都会打出日志，根据日志都能快速解决问题，否则，只能去重现问题，然后去定位问题，最后solve。 作者 [soar]2017 年 06月 08日 link &amp; more:http://dbaplus.cn/news-21-625-1.htmlhttps://www.zhihu.com/question/43416744]]></content>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux IO]]></title>
    <url>%2F2017%2F06%2F07%2FLinux-IO%2F</url>
    <content type="text"><![CDATA[是时候表演真正的技术了-linux IO 本文讨论的背景是Linux环境下的Network IO。本文最重要的参考文献是Richard Stevens的“UNIX® Network Programming Volume 1, Third Edition: The Sockets Networking ”，6.2节“I/O Models”. Stevens在文章中一共比较了五种IO Model： blocking IO nonblocking IO IO multiplexing signal driven IO asynchronous IO 由于signal driven IO在实际中并不常用，所我这只提及剩下的四种IO Model。再说一下IO发生时涉及的对象和步骤。对于一个network IO (这里我们以read举例)，它会涉及到两个系统对象，一个是调用这个IO的process (or thread)，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段： 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) 记住这两点很重要，因为这些IO Model的区别就是在两个阶段上各有不同的情况。 Blocking IO在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样： 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据。对于network io来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的UDP包），这个时候kernel就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 Non-Blocking IOlinux下，可以通过设置socket使其变为non-blocking。当对一个non-blockingsocket执行读操作时，流程是这个样子： 从图中可以看出，当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error.从用户进程角度讲，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的systemcall，那么它马上就将数据拷贝到了用户内存，然后返回。所以，用户进程其实是需要不断的主动询问kernel数据好了没有。 IO MultiplexingIO multiplexing这个词可能有点陌生，但是如果我说select，epoll，大概就都能明白了。有些地方也称这种IO方式为event drivenIO。我们都知道，select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select/epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。它的流程如图： 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。这个图和blockingIO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blockingIO只调用了一个systemcall(recvfrom)。但是，用select的优势在于它可以同时处理多个connection。（多说一句。所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blockin IO的webserver性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。） 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 Asynchronous I/Olinux下的asynchronous IO其实用得很少。先看一下它的流程： 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 到目前为止，已经将四个IO Model都介绍完了。现在回过头来回答最初的那几个问题：blocking和non-blocking的区别在哪，synchronous IO和asynchronous IO的区别在哪。 1. blocking vs non-blocking前面的介绍中其实已经很明确的说明了这两者的区别。调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。 ###2. synchronous IO vs asynchronous IO 在讲她们之间的区别之前，需要先给出两者的定义。Stevens给出的定义（其实是POSIX的定义）是这样子的： A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;An asynchronous I/O operation does not cause the requesting process to be blocked; 两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。可能有人会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。 各个IO Model的比较如图所示： 经过上面的介绍，会发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。 作者 [soar]2017 年 06月 06日]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zero Copy]]></title>
    <url>%2F2017%2F05%2F14%2Fzero-copy%2F</url>
    <content type="text"><![CDATA[Zero Copy分析 传统的I/O使用传统的I/O程序读取文件内容, 并写入到另一个文件(或Socket), 如下程序: 12File.read(fileDesc, buf, len);Socket.send(socket, buf, len); 会有较大的性能开销, 主要表现在一下两方面: 上下文切换(context switch), 此处有4次用户态和内核态的切换 Buffer内存开销, 一个是应用程序buffer, 另一个是系统读取buffer以及socket buffer 其运行示意图如下 1) 先将文件内容从磁盘中拷贝到操作系统buffer 2) 再从操作系统buffer拷贝到程序应用buffer 3) 从程序buffer拷贝到socket buffer(也可以是file) 4) 从socket buffer拷贝到协议引擎. 上下文切换示意图如下 1) 调用read(), 程序切换到内核态 2) read()调用完毕, 返回数据, 程序切换回用户态 3) 调用send(), 程序切换到内核态 4) send()完毕, 程序切换回用户态 操作系统使用 read buffer 的好处是”预读”, 当你的程序需要对文件数据做处理, 并且每次读取的数据小于read buffer 的时候, 可以先将多数数据预读到 read buffer, 这样程序在读取的时候效率会更高. 但是当你需要读取的数据大于操作系统的read buffer的时候, read buffer则会成为累赘. 另外, 在你的程序不需要处理数据, 而仅仅只是做数据转移的时候, 程序buffer则会成为不必要的开销. 上面会涉及到多次上下文切换以及多次数据拷贝, 很大一部分cpu及内存开销是可以避免的, 于是有了zerocopy技术. ZeroCopyzerocopy技术省去了将操作系统的read buffer拷贝到程序的buffer, 以及从程序buffer拷贝到socket buffer的步骤, 直接将 read buffer 拷贝到 socket buffer. java 的 FileChannel.transferTo() 方法就是这样的实现, 这个实现是依赖于操作系统底层的sendFile()实现的. 1public void transferTo(long position, long count, WritableByteChannel target); 他的底层调用的是系统调用sendFile()方法 12#include &lt;sys/socket.h&gt;ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count); 其运行示意图如下 上下文切换示意图如下 这样, 省去了两次buffer的copy, 并且上下文切换降到了2次(调用transferTo()进入内核态, 调用完毕返回用户态) Linux 2.4 及以后的内核, 又做了改进, 不再使用socket buffer, 而是直接将read buffer数据拷贝到协议引擎, 而socket buffer只会记录数据位置的描述符和数据长度,如下 作者 [soar]2017 年 05月 14日 参考献文如下[1] http://www.ibm.com/developerworks/library/j-zerocopy/]]></content>
      <tags>
        <tag>zero copy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客使用教程]]></title>
    <url>%2F2017%2F05%2F13%2Ftutorial%2F</url>
    <content type="text"><![CDATA[环境配置1.安装 node和npm，自行百度2.安装hexo-clinpm install -g hexo-cli 项目配置1.进入项目cd zhongruanhulian 2.初始化hexo hexo init 3.下载所需libnpm install ├── _config.yml //网站的 配置 信息，您可以在此配置大部分的参数。├── package.json├── scaffolds //模版 文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件。├── source //资源文件夹是存放用户资源的地方。| ├── tags| └── _posts└── themes //主题 文件夹。Hexo 会根据主题来生成静态页面。 博客开发1.新建文章（创建一个Hello World）$ hexo new “Hello World”在/source/_post里添加hello-world.md文件，之后新建的文章都将存放在此目录下。 2.如何需要创建标签或者目录可以使用以下命令（目前已有目录和标签）hexo new page “tags”hexo new page “categories” 3.生成网站hexo generate此时会将/source的.md文件生成到/public中，形成网站的静态文件，这里的文件就是要发布到线上的文件。 4.部署本地服务器hexo server输入http://localhost:4000即可查看网站。 发布线上（这里使用ant部署线上项目，需要安装ant）ant -f upload.xml 总结每次新建好文章，编写完了，先执行hexo server命令，在本地看看效果如如何，如果没问题再执行hexo generate命令重新生成静态文件，最后执行ant -f upload.xml命令把重新生成的静态文件发布线上。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Cmd Markdown]]></title>
    <url>%2F2017%2F05%2F13%2FCmd%20Markdown%2F</url>
    <content type="text"><![CDATA[欢迎使用 Cmd Markdown 编辑阅读器 我们理解您需要更便捷更高效的工具记录思想，整理笔记、知识，并将其中承载的价值传播给他人，Cmd Markdown 是我们给出的答案 —— 我们为记录思想和分享知识提供更专业的工具。 您可以使用 Cmd Markdown： 整理知识，学习笔记 发布日记，杂文，所见所想 撰写发布技术文稿（代码支持） 撰写发布学术论文（LaTeX 公式支持） 除了您现在看到的这个 Cmd Markdown 在线版本，您还可以前往以下网址下载： Windows/Mac/Linux 全平台客户端 请保留此份 Cmd Markdown 的欢迎稿兼使用说明，如需撰写新稿件，点击顶部工具栏右侧的 新文稿 或者使用快捷键 Ctrl+Alt+N。 什么是 MarkdownMarkdown 是一种方便记忆、书写的纯文本标记语言，用户可以使用这些标记符号以最小的输入代价生成极富表现力的文档：譬如您正在阅读的这份文档。它使用简单的符号标记不同的标题，分割不同的段落，粗体 或者 斜体 某些文字，更棒的是，它还可以 1. 制作一份待办事宜 Todo 列表 [ ] 支持以 PDF 格式导出文稿 [ ] 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率 [x] 新增 Todo 列表功能 [x] 修复 LaTex 公式渲染问题 [x] 新增 LaTex 公式编号功能 2. 书写一个质能守恒公式[^LaTeX]$$E=mc^2$$ 3. 高亮一段代码[^code]1234567@requires_authorizationclass SomeClass: passif __name__ == '__main__': # A comment print 'hello world' 4. 高效绘制 流程图12345678st=&gt;start: Startop=&gt;operation: Your Operationcond=&gt;condition: Yes or No?e=&gt;endst-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op 5. 高效绘制 序列图123Alice-&gt;Bob: Hello Bob, how are you?Note right of Bob: Bob thinksBob--&gt;Alice: I am good thanks! 6. 高效绘制 甘特图12345678910111213title 项目开发流程section 项目确定 需求分析 :a1, 2016-06-22, 3d 可行性报告 :after a1, 5d 概念验证 : 5dsection 项目实施 概要设计 :2016-07-05 , 5d 详细设计 :2016-07-08, 10d 编码 :2016-07-15, 10d 测试 :2016-07-22, 5dsection 发布验收 发布: 2d 验收: 3d 7. 绘制表格 项目 价格 数量 计算机 \$1600 5 手机 \$12 12 管线 \$1 234 8. 更详细语法说明想要查看更详细的语法说明，可以参考我们准备的 Cmd Markdown 简明语法手册，进阶用户可以参考 Cmd Markdown 高阶语法手册 了解更多高级功能。 总而言之，不同于其它 所见即所得 的编辑器：你只需使用键盘专注于书写文本内容，就可以生成印刷级的排版格式，省却在键盘和工具栏之间来回切换，调整内容和格式的麻烦。Markdown 在流畅的书写和印刷级的阅读体验之间找到了平衡。 目前它已经成为世界上最大的技术分享网站 GitHub 和 技术问答网站 StackOverFlow 的御用书写格式。 什么是 Cmd Markdown您可以使用很多工具书写 Markdown，但是 Cmd Markdown 是这个星球上我们已知的、最好的 Markdown 工具——没有之一 ：）因为深信文字的力量，所以我们和你一样，对流畅书写，分享思想和知识，以及阅读体验有极致的追求，我们把对于这些诉求的回应整合在 Cmd Markdown，并且一次，两次，三次，乃至无数次地提升这个工具的体验，最终将它演化成一个 编辑/发布/阅读 Markdown 的在线平台——您可以在任何地方，任何系统/设备上管理这里的文字。 1. 实时同步预览我们将 Cmd Markdown 的主界面一分为二，左边为编辑区，右边为预览区，在编辑区的操作会实时地渲染到预览区方便查看最终的版面效果，并且如果你在其中一个区拖动滚动条，我们有一个巧妙的算法把另一个区的滚动条同步到等价的位置，超酷！ 2. 编辑工具栏也许您还是一个 Markdown 语法的新手，在您完全熟悉它之前，我们在 编辑区 的顶部放置了一个如下图所示的工具栏，您可以使用鼠标在工具栏上调整格式，不过我们仍旧鼓励你使用键盘标记格式，提高书写的流畅度。 3. 编辑模式完全心无旁骛的方式编辑文字：点击 编辑工具栏 最右侧的拉伸按钮或者按下 Ctrl + M，将 Cmd Markdown 切换到独立的编辑模式，这是一个极度简洁的写作环境，所有可能会引起分心的元素都已经被挪除，超清爽！ 4. 实时的云端文稿为了保障数据安全，Cmd Markdown 会将您每一次击键的内容保存至云端，同时在 编辑工具栏 的最右侧提示 已保存 的字样。无需担心浏览器崩溃，机器掉电或者地震，海啸——在编辑的过程中随时关闭浏览器或者机器，下一次回到 Cmd Markdown 的时候继续写作。 5. 离线模式在网络环境不稳定的情况下记录文字一样很安全！在您写作的时候，如果电脑突然失去网络连接，Cmd Markdown 会智能切换至离线模式，将您后续键入的文字保存在本地，直到网络恢复再将他们传送至云端，即使在网络恢复前关闭浏览器或者电脑，一样没有问题，等到下次开启 Cmd Markdown 的时候，她会提醒您将离线保存的文字传送至云端。简而言之，我们尽最大的努力保障您文字的安全。 6. 管理工具栏为了便于管理您的文稿，在 预览区 的顶部放置了如下所示的 管理工具栏： 通过管理工具栏可以： 发布：将当前的文稿生成固定链接，在网络上发布，分享 新建：开始撰写一篇新的文稿 删除：删除当前的文稿 导出：将当前的文稿转化为 Markdown 文本或者 Html 格式，并导出到本地 列表：所有新增和过往的文稿都可以在这里查看、操作 模式：切换 普通/Vim/Emacs 编辑模式 7. 阅读工具栏 通过 预览区 右上角的 阅读工具栏，可以查看当前文稿的目录并增强阅读体验。 工具栏上的五个图标依次为： 目录：快速导航当前文稿的目录结构以跳转到感兴趣的段落 视图：互换左边编辑区和右边预览区的位置 主题：内置了黑白两种模式的主题，试试 黑色主题，超炫！ 阅读：心无旁骛的阅读模式提供超一流的阅读体验 全屏：简洁，简洁，再简洁，一个完全沉浸式的写作和阅读环境 8. 阅读模式在 阅读工具栏 点击 或者按下 Ctrl+Alt+M 随即进入独立的阅读模式界面，我们在版面渲染上的每一个细节：字体，字号，行间距，前背景色都倾注了大量的时间，努力提升阅读的体验和品质。 9. 标签、分类和搜索在编辑区任意行首位置输入以下格式的文字可以标签当前文档： 标签： 未分类 标签以后的文稿在【文件列表】（Ctrl+Alt+F）里会按照标签分类，用户可以同时使用键盘或者鼠标浏览查看，或者在【文件列表】的搜索文本框内搜索标题关键字过滤文稿，如下图所示： 10. 文稿发布和分享在您使用 Cmd Markdown 记录，创作，整理，阅读文稿的同时，我们不仅希望它是一个有力的工具，更希望您的思想和知识通过这个平台，连同优质的阅读体验，将他们分享给有相同志趣的人，进而鼓励更多的人来到这里记录分享他们的思想和知识，尝试点击 (Ctrl+Alt+P) 发布这份文档给好友吧！ 再一次感谢您花费时间阅读这份欢迎稿，点击 (Ctrl+Alt+N) 开始撰写新的文稿吧！祝您在这里记录、阅读、分享愉快！ 作者 @ghosert2016 年 07月 07日 [^LaTeX]: 支持 LaTeX 编辑显示支持，例如：$\sum_{i=1}^n a_i=0$， 访问 MathJax 参考更多使用方法。 [^code]: 代码高亮功能支持包括 Java, Python, JavaScript 在内的，四十一种主流编程语言。]]></content>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSD-HDD性能差异]]></title>
    <url>%2F2017%2F05%2F13%2Fssd-hdd%2F</url>
    <content type="text"><![CDATA[SSD和HDD性能差异 对于我们学软件的来说，懂点硬件知识在某种场合发挥的作用比软件还大。SSD和HDD对于大多数学计算机的都不陌生，但是要说出她们之间具体的性能差异，可能就有点难了。这里就详细介绍下她们在一些场合下的性能差异，具体场合如下： 开机 游戏 电影 音乐 总结 开机 游戏 电影 音乐 相片 总结]]></content>
      <tags>
        <tag>hardware</tag>
      </tags>
  </entry>
</search>
